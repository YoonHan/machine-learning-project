{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref : https://github.com/developer0hye/Custom-CNN-based-Image-Classification-in-PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Data\n",
    "validation_split =  0.2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "# image_dir = './Data/resized'\n",
    "image_dir = './Data/images/images'\n",
    "\n",
    "# Initial Value\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "learning_rate = 0.00001 \n",
    "\n",
    "# Running Type : debug / Operation\n",
    "running_type = \"Operation\"\n",
    "# running_type = \"debug\"\n",
    "\n",
    "# data_type : drawing / cifar10 / kuroro\n",
    "data_type = \"drawing\"\n",
    "# data_type = \"cifar10\"\n",
    "# data_type = \"kuroko\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Resizing\n",
    "img_h, img_w = 128, 128\n",
    "imgs = []\n",
    "imgs_label = []\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def read_dataset(self):\n",
    "\n",
    "        all_img_files = []\n",
    "        all_labels = []\n",
    "        all_class_names = set()\n",
    "        \n",
    "        # for debug\n",
    "        now = 0\n",
    "        count = 0\n",
    "        \n",
    "        class_names = os.walk(self.dataset_path).__next__()[1]        \n",
    "        for index, class_name in enumerate(class_names):\n",
    "            label = index\n",
    "            img_dir = os.path.join(self.dataset_path, class_name)\n",
    "            img_files = os.walk(img_dir).__next__()[2]\n",
    "            for img_file in img_files:\n",
    "                img_file = os.path.join(img_dir, img_file)\n",
    "                img = Image.open(img_file)\n",
    "                if running_type == \"debug\":\n",
    "                    if label+1 > 5:\n",
    "                        break;\n",
    "                    if count < 1000:\n",
    "                        all_img_files.append(img_file)\n",
    "                        all_labels.append(label)\n",
    "                        all_class_names.add(class_name)\n",
    "                    elif now != label:\n",
    "                        now = label\n",
    "                        count = -1\n",
    "                    \n",
    "                    count += 1\n",
    "                else:\n",
    "                    if img is not None:\n",
    "                        all_img_files.append(img_file)\n",
    "                        all_labels.append(label)\n",
    "                        all_class_names.add(class_name)\n",
    "                    \n",
    "        \n",
    "        return all_img_files, all_labels, len(all_img_files), len(all_class_names)\n",
    "\n",
    "    def __init__(self, dataset_path, transforms=None):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.image_files_path, self.labels, self.length, self.num_classes = self.read_dataset()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_files_path[index])\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return {'image': image, 'label': self.labels[index]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_type == \"drawing\":\n",
    "    transforms = transforms.Compose([transforms.Resize((img_h, img_w)),\n",
    "                                           transforms.RandomRotation(10.),\n",
    "                                           transforms.ToTensor()])\n",
    "\n",
    "    # Split data to train and validation\n",
    "    dataset = CustomImageDataset(dataset_path=image_dir, transforms=transforms)\n",
    "\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                               sampler=train_sampler)\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "\n",
    "elif data_type == \"cifar10\":\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data_cifar10', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data_cifar10', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    validation_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    trainset.num_classes = len(classes)\n",
    "elif data_type == \"kuroko\":\n",
    "    transforms_train = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                           transforms.RandomRotation(10.),\n",
    "                                           transforms.ToTensor()])\n",
    "\n",
    "    transforms_test = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                          transforms.ToTensor()])\n",
    "\n",
    "    trainset = CustomImageDataset(dataset_path=\"./data_kuroko/train\", transforms=transforms_train)\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    testset = CustomImageDataset(dataset_path=\"./data_kuroko/test\", transforms=transforms_test)\n",
    "    validation_loader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_loader)\n",
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data length : 8118 = 6495(train) + 1623(test)\n",
      "num_classes :  49\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "if data_type == \"drawing\":\n",
    "    print(\"All data length : {} = {}(train) + {}(test)\" .format(len(dataset), train_indices.__len__(), val_indices.__len__()))\n",
    "    print(\"num_classes : \", dataset.num_classes)\n",
    "    plt.imshow(dataset[2].get('image').permute(1, 2, 0)); # 이미지 그리기\n",
    "elif data_type == \"cifar10\":\n",
    "    print(\"train length : \", len(trainset))\n",
    "    print(\"validation length : \" , len(testset))\n",
    "    print(\"class length : \", trainset.num_classes)\n",
    "if data_type == \"kuroko\":\n",
    "    print(\"All data length : {} = {}(train) + {}(test)\" .format(len(trainset) + len(testset), len(trainset),  len(testset)))\n",
    "    print(\"num_classes : \", trainset.num_classes)\n",
    "    plt.imshow(trainset[2].get('image').permute(1, 2, 0)); # 이미지 그리기\n",
    "\n",
    "# for i_batch, item in enumerate(train_loader):\n",
    "#     print(item['label'])\n",
    "    \n",
    "# for i_batch, item in enumerate(validation_loader):\n",
    "#     print(item['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model : VGG19\n",
    "class VGG19(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG19, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.FC1 = nn.Sequential(\n",
    "#             nn.Linear(512, 4096),\n",
    "            nn.Linear(8192, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.FC2 = nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.FC3 = nn.Sequential(\n",
    "            nn.Linear(4096, num_classes),\n",
    "            nn.BatchNorm1d(num_classes),\n",
    "            nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "#         print(\"out : \", out.shape)\n",
    "        out = self.FC1(out)\n",
    "        out = self.FC2(out)\n",
    "        out = self.FC3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer : Adam\n",
    "class Adam:\n",
    "    \"\"\"Adam (http://arxiv.org/abs/1412.6980v8)\"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = {}, {}\n",
    "            for key, val in params.items():\n",
    "                self.m[key] = np.zeros_like(val)\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "\n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2 ** self.iter) / (1.0 - self.beta1 ** self.iter)\n",
    "\n",
    "        for key in params.keys():\n",
    "            # self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]\n",
    "            # self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)\n",
    "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n",
    "            self.v[key] += (1 - self.beta2) * (grads[key] ** 2 - self.v[key])\n",
    "\n",
    "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if data_type==\"drawing\":\n",
    "    num_classes = dataset.num_classes\n",
    "elif data_type ==  \"kuroro\":\n",
    "    num_classes = trainset.num_classes\n",
    "vgg19 = VGG19(num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss Function\n",
    "Loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(vgg19.parameters(), lr=learning_rate)\n",
    "# optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 998 test images: 51.503006012024045 %\n",
      "Epoch [1/10], Loss: 1.4599\n",
      "Test Accuracy of the model on the 998 test images: 59.519038076152306 %\n",
      "Epoch [2/10], Loss: 1.3749\n",
      "Test Accuracy of the model on the 998 test images: 64.62925851703407 %\n",
      "Epoch [3/10], Loss: 1.4294\n",
      "Test Accuracy of the model on the 998 test images: 66.63326653306613 %\n",
      "Epoch [4/10], Loss: 1.3536\n",
      "Test Accuracy of the model on the 998 test images: 68.13627254509018 %\n",
      "Epoch [5/10], Loss: 1.4051\n",
      "Test Accuracy of the model on the 998 test images: 69.13827655310621 %\n",
      "Epoch [6/10], Loss: 1.3740\n",
      "Test Accuracy of the model on the 998 test images: 70.54108216432866 %\n",
      "Epoch [7/10], Loss: 1.3579\n",
      "Test Accuracy of the model on the 998 test images: 72.54509018036072 %\n",
      "Epoch [8/10], Loss: 1.3713\n",
      "Test Accuracy of the model on the 998 test images: 73.44689378757515 %\n",
      "Epoch [9/10], Loss: 1.3982\n",
      "Test Accuracy of the model on the 998 test images: 73.94789579158316 %\n",
      "Epoch [10/10], Loss: 1.2343\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "correct_mid = 0 \n",
    "\n",
    "for e in range(num_epochs):\n",
    "    for i_batch, item in enumerate(train_loader): # i_batch : i번째 batch, item : 해당 item, batch_size개\n",
    "        images = item['image'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = vgg19(images)\n",
    "        loss = Loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 중간 집계\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += len(labels)        \n",
    "\n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}' .format(e + 1, num_epochs, loss.item()))\n",
    "    correct = 0\n",
    "    total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 2, 2, 2, 2, 4, 0, 2]) (labels) vs tensor([4, 2, 2, 2, 2, 4, 0, 2]) (predicted) \n",
      "tensor([2, 2, 2, 2, 4, 2, 2, 2]) (labels) vs tensor([2, 2, 2, 2, 4, 2, 2, 2]) (predicted) \n",
      "tensor([4, 1, 1, 4, 1, 2, 1, 4]) (labels) vs tensor([4, 1, 1, 4, 1, 1, 1, 4]) (predicted) \n",
      "tensor([4, 4, 4, 3, 2, 1, 2, 2]) (labels) vs tensor([4, 4, 1, 3, 2, 3, 1, 2]) (predicted) \n",
      "tensor([4, 0, 2, 2, 4, 0, 2, 1]) (labels) vs tensor([4, 0, 2, 2, 4, 0, 2, 1]) (predicted) \n",
      "tensor([1, 2, 2, 3, 2, 1, 2, 0]) (labels) vs tensor([1, 2, 2, 3, 2, 1, 3, 1]) (predicted) \n",
      "tensor([2, 2, 2, 4, 2, 2, 4, 1]) (labels) vs tensor([1, 2, 2, 4, 2, 2, 4, 4]) (predicted) \n",
      "tensor([2, 3, 2, 2, 1, 2, 1, 2]) (labels) vs tensor([2, 3, 2, 2, 1, 2, 1, 1]) (predicted) \n",
      "tensor([2, 2, 2, 4, 2, 2, 2, 2]) (labels) vs tensor([2, 2, 2, 4, 2, 2, 2, 2]) (predicted) \n",
      "tensor([4, 2, 3, 4, 2, 0, 1, 2]) (labels) vs tensor([4, 2, 2, 4, 2, 0, 1, 2]) (predicted) \n",
      "tensor([2, 2, 2, 2, 0, 4, 2, 4]) (labels) vs tensor([2, 2, 2, 0, 0, 4, 1, 4]) (predicted) \n",
      "tensor([2, 4, 4, 4, 2, 0, 0, 3]) (labels) vs tensor([2, 4, 4, 3, 1, 0, 0, 3]) (predicted) \n",
      "tensor([0, 2, 2, 2, 2, 2, 2, 2]) (labels) vs tensor([0, 2, 2, 2, 1, 2, 2, 2]) (predicted) \n",
      "tensor([2, 1, 2, 2, 2, 2, 1, 3]) (labels) vs tensor([2, 1, 3, 2, 2, 2, 1, 2]) (predicted) \n",
      "tensor([2, 1, 0, 2, 4, 4, 4, 2]) (labels) vs tensor([4, 4, 2, 2, 1, 2, 4, 2]) (predicted) \n",
      "tensor([2, 1, 2, 4, 0, 1, 2, 2]) (labels) vs tensor([0, 2, 2, 4, 3, 1, 2, 2]) (predicted) \n",
      "tensor([4, 2, 4, 2, 2, 2, 2, 4]) (labels) vs tensor([4, 2, 1, 2, 2, 2, 2, 4]) (predicted) \n",
      "tensor([2, 4, 4, 4, 2, 2, 4, 2]) (labels) vs tensor([4, 3, 4, 1, 2, 2, 4, 1]) (predicted) \n",
      "tensor([4, 4, 4, 2, 1, 2, 2, 0]) (labels) vs tensor([4, 4, 3, 0, 1, 2, 2, 0]) (predicted) \n",
      "tensor([0, 2, 4, 2, 2, 2, 2, 1]) (labels) vs tensor([3, 1, 1, 2, 2, 2, 2, 1]) (predicted) \n",
      "tensor([2, 1, 2, 4, 4, 2, 4, 2]) (labels) vs tensor([2, 2, 2, 4, 4, 2, 4, 0]) (predicted) \n",
      "tensor([3, 2, 4, 1, 2, 3, 2, 4]) (labels) vs tensor([3, 2, 4, 1, 2, 2, 2, 3]) (predicted) \n",
      "tensor([2, 2, 2, 2, 4, 2, 4, 2]) (labels) vs tensor([3, 1, 2, 2, 4, 1, 4, 2]) (predicted) \n",
      "tensor([2, 2, 2, 2, 0, 2, 2, 2]) (labels) vs tensor([0, 2, 2, 2, 3, 2, 2, 2]) (predicted) \n",
      "tensor([4, 2, 1, 2, 4, 2, 2, 3]) (labels) vs tensor([4, 1, 1, 4, 4, 2, 1, 2]) (predicted) \n",
      "tensor([1, 2, 1, 2, 2, 2, 4, 2]) (labels) vs tensor([1, 2, 2, 2, 2, 2, 4, 2]) (predicted) \n",
      "tensor([4, 2, 1, 2, 2, 4, 2, 4]) (labels) vs tensor([4, 2, 1, 3, 3, 0, 2, 1]) (predicted) \n",
      "tensor([2, 4, 4, 2, 2, 2, 2, 2]) (labels) vs tensor([2, 4, 4, 1, 2, 2, 2, 2]) (predicted) \n",
      "tensor([3, 2, 4, 2, 4, 2, 2, 4]) (labels) vs tensor([3, 2, 1, 2, 1, 2, 2, 1]) (predicted) \n",
      "tensor([2, 0, 2, 2, 2, 0, 2, 4]) (labels) vs tensor([2, 0, 1, 2, 2, 0, 2, 3]) (predicted) \n",
      "tensor([3, 2, 2, 2, 4, 4, 2, 1]) (labels) vs tensor([3, 4, 2, 2, 1, 4, 2, 1]) (predicted) \n",
      "tensor([2]) (labels) vs tensor([4]) (predicted) \n",
      "Test Accuracy of the model on the 249 test images: 75.1004016064257 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "vgg19.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "#    for item in train_loader:\n",
    "    for item in validation_loader:\n",
    "        images = item['image'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        outputs = vgg19(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # print(\"{} (labels) vs {} (predicted) \" .format(labels, predicted))\n",
    "\n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
